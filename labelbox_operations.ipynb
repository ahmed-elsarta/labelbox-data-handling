{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labelbox Data handling scripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## convert labelbox ndjson to YOLO format \n",
    "where each corresponding image has a .txt file with the same name and the label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found file img (1).jpg with label 2\n",
      "found file img (2).jpg with label 2\n",
      "found file img (3).jpg with label 2\n",
      "found file img (9).jpg with label 2\n",
      "found file img (10).jpg with label 2\n",
      "found file img (11).jpg with label 1\n",
      "found file img (12).jpg with label 2\n",
      "found file img (13).jpg with label 2\n",
      "found file img (14).jpg with label 2\n",
      "found file img (16).jpg with label 1\n",
      "found file img (17).jpg with label 2\n",
      "found file img (18).jpg with label 2\n",
      "found file img (19).jpg with label 2\n",
      "found file img (20).jpg with label 2\n",
      "found file img (21).jpg with label 2\n",
      "found file img (22).jpg with label 2\n",
      "found file img (23).jpg with label 2\n",
      "found file img (24).jpg with label 1\n",
      "found file img (25).jpg with label 1\n",
      "found file img (26).jpg with label 2\n",
      "found file img (27).jpg with label 2\n",
      "found file img (28).jpg with label 2\n",
      "found file img (35).jpg with label 1\n",
      "found file img (36).jpg with label 2\n",
      "Skipping annotation with name: Needs graft?\n",
      "found file img (37).jpg with label 2\n",
      "found file img (38).jpg with label 2\n",
      "Skipping annotation with name: Needs graft?\n",
      "found file img (39).jpg with label 2\n",
      "found file img (40).jpg with label 1\n",
      "found file img (41).jpg with label 2\n",
      "found file img (42).jpg with label 2\n",
      "found file img (43).jpg with label 1\n",
      "found file img (44).jpg with label 2\n",
      "found file img (45).jpg with label 2\n",
      "found file img (46).jpg with label 2\n",
      "found file img (47).jpg with label 2\n",
      "found file img (48).jpg with label 2\n",
      "found file img (49).jpg with label 2\n",
      "found file img (50).jpg with label 2\n",
      "found file img (51).jpg with label 2\n",
      "found file img (52).jpg with label 1\n",
      "found file img (53).jpg with label 1\n",
      "found file img (54).jpg with label None\n",
      "found file img (55).jpg with label 1\n",
      "found file img (56).jpg with label 1\n",
      "found file img (57).jpg with label 2\n",
      "found file img (58).jpg with label 1\n",
      "found file img (59).jpg with label 2\n",
      "found file img (61).jpg with label 2\n",
      "found file img (62).jpg with label 2\n",
      "found file img (63).jpg with label 2\n",
      "found file img (64).jpg with label 2\n",
      "found file img (65).jpg with label 2\n",
      "found file img (66).jpg with label 2\n",
      "found file img (67).jpg with label 2\n",
      "found file img (68).jpg with label 2\n",
      "found file img (69).jpg with label 2\n",
      "found file img (70).jpg with label 2\n",
      "found file img (71).jpg with label 2\n",
      "found file img (72).jpg with label 2\n",
      "found file img (73).jpg with label 2\n",
      "found file img (74).jpg with label 2\n",
      "found file img (75).jpg with label 2\n",
      "found file img (76).jpg with label 2\n",
      "found file img (77).jpg with label 2\n",
      "found file img (78).jpg with label 1\n",
      "found file img (79).jpg with label 2\n",
      "found file img (80).jpg with label 2\n",
      "found file img (81).jpg with label 1\n",
      "found file img (82).jpg with label 1\n",
      "found file img (83).jpg with label 1\n",
      "found file img (85).jpg with label 2\n",
      "found file img (86).jpg with label 2\n",
      "found file img (87).jpg with label 2\n",
      "found file 20220222_103505.jpg with label 2\n",
      "found file 20220222_103516.jpg with label 2\n",
      "found file 20220222_105420.jpg with label 1\n",
      "found file 20220222_105426.jpg with label 1\n",
      "found file 20220328_102939.jpg with label 1\n",
      "found file 20220423_101011.jpg with label 2\n",
      "found file 20220423_101019.jpg with label 1\n",
      "found file 20220423_101025.jpg with label 1\n",
      "found file 20220423_101028.jpg with label 1\n",
      "found file 20220423_101039.jpg with label 1\n",
      "found file 20220423_101617.jpg with label 2\n",
      "found file 20220423_101621.jpg with label 2\n",
      "found file 20220814_131654.jpg with label 1\n",
      "found file 20220816_102442.jpg with label 2\n",
      "found file 20231102_102826.jpg with label 2\n",
      "found file 20231115_145022.jpg with label 1\n",
      "found file 20231115_155800.jpg with label 2\n",
      "found file 20231128_134502.jpg with label 1\n",
      "found file 20231202_154707.jpg with label 1\n",
      "found file 20231206_105203.jpg with label 1\n",
      "found file 20231211_120751.jpg with label 1\n",
      "found file 20231211_124054.jpg with label 2\n",
      "found file 20231218_102108.jpg with label 1\n",
      "found file IMG-20231212-WA0112.jpg with label 2\n",
      "found file IMG-20231212-WA0114.jpg with label 2\n",
      "found file IMG-20231214-WA0105.jpg with label 1\n",
      "found file IMG-20231217-WA0078.jpg with label 2\n",
      "found file IMG-20231217-WA0079.jpg with label 2\n",
      "found file IMG-20231218-WA0063 - Copy.jpg with label 1\n",
      "found file 20220610_152807 - Copy.jpg with label 2\n",
      "found file 20220610_152807.jpg with label 2\n",
      "found file 20220807_133245.jpg with label 1\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import shutil\n",
    "# Specify the path to your ndjson file\n",
    "input_path = 'export_20240404.ndjson' #change these paths\n",
    "images_dir = \"../New dataset/elkasr_elaini_20230315/\"\n",
    "output_dir = 'kasr_aini_20240404_full'\n",
    "\n",
    "\n",
    "# Function to convert Roman numerals to Arabic numerals as per your mapping\n",
    "def roman_to_arabic(roman):\n",
    "    mapping = {'I': 0, 'i':0, \n",
    "               'IIb': 1, 'iia':1,\n",
    "               'IIa': 1, 'iib':1,\n",
    "                'III': 2, 'iii':2}\n",
    "    return mapping.get(roman, None)\n",
    "\n",
    "# Open the ndjson file\n",
    "with open(input_path, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Process each line (which is a separate JSON object)\n",
    "for line in lines:\n",
    "    data = json.loads(line)\n",
    "\n",
    "    # Extract the required values\n",
    "    external_id = data['data_row']['external_id']\n",
    "    degree = None\n",
    "\n",
    "    # The \"degree\" value is nested, so we need to dig a bit deeper\n",
    "    for project in data['projects'].values():\n",
    "        for label in project['labels']:\n",
    "            for classification in label['annotations']['classifications']:\n",
    "                if classification['name'] == 'degree':\n",
    "                    degree = roman_to_arabic(classification['radio_answer']['name'])\n",
    "                    break\n",
    "                else:\n",
    "                    print(f\"Skipping annotation with name: {classification['name']}\")\n",
    "\n",
    "    # Check if the filename ends with .jpg\n",
    "    if external_id.endswith('.jpg'):\n",
    "        # find the file in the images directory or its subdirectories\n",
    "        for root, dirs, files in os.walk(images_dir):\n",
    "            if external_id in files:\n",
    "                print (\"found file\", external_id, \"with label\", degree)\n",
    "                # Copy the file to the output directory\n",
    "                os.system(f'cp \"{os.path.join(root, external_id)}\" \"{output_dir}\"')\n",
    "                shutil.copy(os.path.join(root, external_id), output_dir)                \n",
    "                break\n",
    "        # Create a .txt file with the same name\n",
    "        filename = os.path.join(output_dir, external_id.replace('.jpg', '.txt'))\n",
    "        # Write the label to the .txt file\n",
    "        with open(filename, 'w') as txtfile:\n",
    "            txtfile.write(str(degree))\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling mask data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content Type: image/png\n",
      "Mask image saved successfully: mask_images\\img (35)_III.jpg\n",
      "Content Type: image/png\n",
      "Mask image saved successfully: mask_images\\img (35)_IIa.jpg\n",
      "Content Type: image/png\n",
      "Mask image saved successfully: mask_images\\img (35)_IIa.jpg\n",
      "Content Type: image/png\n",
      "Mask image saved successfully: mask_images\\img (35)_III.jpg\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import io\n",
    "import json\n",
    "import os\n",
    "\n",
    "headers = {\n",
    "    'Authorization': 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VySWQiOiJjbHBoZXdxbHMwNGdzMDd5czU1ejA5bWZhIiwib3JnYW5pemF0aW9uSWQiOiJjbHBoZXdxbDgwNGdyMDd5czlmODRmOWNzIiwiYXBpS2V5SWQiOiJjbHVsejVmNzYwNGx6MDd3N2d0bHFlbmw3Iiwic2VjcmV0IjoiZjc2OGNhODQ2YzI0OGFhNzFmODk3NWU0YjdkOWYwYzUiLCJpYXQiOjE3MTIyNzk3NDUsImV4cCI6MjM0MzQzMTc0NX0.-COC3GIHm5oG9Kp1wfNG2R9ZsPVlX6rMMJJyBU_9PzE'\n",
    "}\n",
    "\n",
    "# Function to fetch mask image from URL with authentication\n",
    "def fetch_mask_image(url, headers=None):\n",
    "    response = requests.get(url, headers=headers, stream=True)\n",
    "    if response.status_code == 200:\n",
    "        content_type = response.headers.get('content-type')\n",
    "        print(\"Content Type:\", content_type)\n",
    "        if 'image' in content_type:\n",
    "            try:\n",
    "                img = Image.open(response.raw)\n",
    "                return img\n",
    "            except Exception as e:\n",
    "                print(\"Error:\", e)\n",
    "                return None\n",
    "        else:\n",
    "            print(\"Error: Response is not an image.\")\n",
    "            return None\n",
    "    else:\n",
    "        print(f\"Error: Unable to fetch image. Status code: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "# Function to combine masks with similar labels\n",
    "def combine_masks(masks):\n",
    "    combined_mask = np.zeros_like(masks[0], dtype=np.uint8)\n",
    "    for mask in masks:\n",
    "        combined_mask += mask\n",
    "    combined_mask = np.clip(combined_mask, 0, 255)\n",
    "    return combined_mask\n",
    "\n",
    "# Parse the provided JSON data\n",
    "json_data = '''\n",
    "{\"data_row\": {\"id\": \"cltsuivlt0y6b084095ayxe92\", \"external_id\": \"img (35).jpg\", \"row_data\": \"https://storage.labelbox.com/clphewql804gr07ys9f84f9cs%2F4f5fda11-0dc3-fd85-5838-74aed3bdb6d3-img%20(35).jpg?Expires=1712279243174&KeyName=labelbox-assets-key-3&Signature=iHP0cfdd5tk2ZSr0giP6kz7pm90\", \"details\": {\"dataset_id\": \"cltsu739100240840e0mn9n78\", \"dataset_name\": \"KA_20240315\", \"created_at\": \"2024-03-15T16:00:56.389+00:00\", \"updated_at\": \"2024-03-15T16:00:57.581+00:00\", \"last_activity_at\": \"2024-04-01T23:16:18.000+00:00\", \"created_by\": \"ahmed.elsarta00@eng-st.cu.edu.eg\"}}, \"media_attributes\": {\"height\": 1600, \"width\": 483, \"mime_type\": \"image/jpeg\", \"exif_rotation\": \"1\"}, \"attachments\": [], \"projects\": {\"cltspurvz006k070i059o144r\": {\"name\": \"Elkasr ElAini burn images dataset\", \"labels\": [{\"label_kind\": \"Default\", \"version\": \"1.0.0\", \"id\": \"cltyyo3ig0dci07c0c7jr142o\", \"label_details\": {\"created_at\": \"2024-03-19T23:02:19.000+00:00\", \"updated_at\": \"2024-03-19T23:02:19.000+00:00\", \"created_by\": \"ahmed.elsarta00@eng-st.cu.edu.eg\", \"content_last_updated_at\": \"2024-03-19T23:02:19.044+00:00\", \"reviews\": []}, \"annotations\": {\"objects\": [{\"feature_id\": \"cltyyu3dr002w2a6ehax4o6eh\", \"feature_schema_id\": \"clphfkl3n08cy070b9gnb9fjn\", \"name\": \"III\", \"value\": \"iii\", \"annotation_kind\": \"ImageSegmentationMask\", \"classifications\": [], \"mask\": {\"url\": \"https://api.labelbox.com/api/v1/projects/cltspurvz006k070i059o144r/annotations/cltyyu3dr002w2a6ehax4o6eh/index/1/mask\"}, \"composite_mask\": {\"url\": \"https://api.labelbox.com/api/v1/tasks/clukjervj017w074v3q3g62nc/masks/cltyyo9o7002q2a6etlvcrgti/index/1\", \"color_rgb\": [153, 73, 245]}}, {\"feature_id\": \"cltyywdyg00382a6eg1l3k4p5\", \"feature_schema_id\": \"clphfkl3n08cu070b6aa93xqm\", \"name\": \"IIa\", \"value\": \"i_ia\", \"annotation_kind\": \"ImageSegmentationMask\", \"classifications\": [], \"mask\": {\"url\": \"https://api.labelbox.com/api/v1/projects/cltspurvz006k070i059o144r/annotations/cltyywdyg00382a6eg1l3k4p5/index/1/mask\"}, \"composite_mask\": {\"url\": \"https://api.labelbox.com/api/v1/tasks/clukjervj017w074v3q3g62nc/masks/cltyyo9o7002q2a6etlvcrgti/index/1\", \"color_rgb\": [200, 126, 137]}}, {\"feature_id\": \"cltyywunw003c2a6epk2lpygh\", \"feature_schema_id\": \"clphfkl3n08cu070b6aa93xqm\", \"name\": \"IIa\", \"value\": \"i_ia\", \"annotation_kind\": \"ImageSegmentationMask\", \"classifications\": [], \"mask\": {\"url\": \"https://api.labelbox.com/api/v1/projects/cltspurvz006k070i059o144r/annotations/cltyywunw003c2a6epk2lpygh/index/1/mask\"}, \"composite_mask\": {\"url\": \"https://api.labelbox.com/api/v1/tasks/clukjervj017w074v3q3g62nc/masks/cltyyo9o7002q2a6etlvcrgti/index/1\", \"color_rgb\": [63, 173, 118]}}, {\"feature_id\": \"cltyyzo6r003l2a6eup91h0q7\", \"feature_schema_id\": \"clphfkl3n08cy070b9gnb9fjn\", \"name\": \"III\", \"value\": \"iii\", \"annotation_kind\": \"ImageSegmentationMask\", \"classifications\": [], \"mask\": {\"url\": \"https://api.labelbox.com/api/v1/projects/cltspurvz006k070i059o144r/annotations/cltyyzo6r003l2a6eup91h0q7/index/1/mask\"}, \"composite_mask\": {\"url\": \"https://api.labelbox.com/api/v1/tasks/clukjervj017w074v3q3g62nc/masks/cltyyo9o7002q2a6etlvcrgti/index/1\", \"color_rgb\": [212, 41, 81]}}], \"classifications\": [{\"feature_id\": \"cltyz2ece00412a6e3wzfri29\", \"feature_schema_id\": \"clphfkl3n08d0070bg7dx7f4a\", \"name\": \"degree\", \"value\": \"degree\", \"radio_answer\": {\"feature_id\": \"cltyz2ece00402a6eb5oecqjz\", \"feature_schema_id\": \"clphfkl3n08d3070b4h6iez8x\", \"name\": \"IIa\", \"value\": \"i_ia\", \"classifications\": []}}], \"relationships\": []}}]}}}\n",
    "\n",
    "'''\n",
    "\n",
    "data = json.loads(json_data)\n",
    "\n",
    "# Create a directory to save mask images\n",
    "output_dir = \"mask_images\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Iterate over annotations\n",
    "for annotation in data[\"projects\"][\"cltspurvz006k070i059o144r\"][\"labels\"][0][\"annotations\"][\"objects\"]:\n",
    "    if \"mask\" in annotation:  # Check if \"mask\" key exists\n",
    "        mask_url = annotation[\"mask\"][\"url\"]\n",
    "        label_name = annotation[\"name\"]\n",
    "        mask_image = fetch_mask_image(mask_url, headers)\n",
    "        if mask_image is not None:\n",
    "            mask_np = np.array(mask_image)\n",
    "\n",
    "            # Save mask image\n",
    "            mask_filename = f\"{data['data_row']['external_id'][:-4]}_{label_name}.jpg\"\n",
    "            mask_filepath = os.path.join(output_dir, mask_filename)\n",
    "            Image.fromarray(mask_np).save(mask_filepath)\n",
    "            print(f\"Mask image saved successfully: {mask_filepath}\")\n",
    "        else:\n",
    "            print(\"Failed to fetch mask image.\")\n",
    "    else:\n",
    "        print(\"No mask data found for this annotation.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert labelbox export to CSV file with filename and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "\n",
    "# Specify the path to your ndjson file\n",
    "ndjson_file_path = 'export_20240404.ndjson' #change these paths\n",
    "csv_output_path = '../New dataset/kasr_aini_20240404.csv'\n",
    "\n",
    "# Open the ndjson file\n",
    "with open(ndjson_file_path, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "# Prepare for CSV output\n",
    "with open(csv_output_path, 'w', newline='') as csvfile:\n",
    "    fieldnames = ['filename', 'label']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "    writer.writeheader()\n",
    "\n",
    "    # Process each line (which is a separate JSON object)\n",
    "    for line in lines:\n",
    "        data = json.loads(line)\n",
    "\n",
    "        # Extract the required values\n",
    "        external_id = data['data_row']['external_id']\n",
    "        degree = None\n",
    "\n",
    "        # The \"degree\" value is nested, so we need to dig a bit deeper\n",
    "        for project in data['projects'].values():\n",
    "            for label in project['labels']:\n",
    "                for classification in label['annotations']['classifications']:\n",
    "                    if classification['name'] == 'degree':\n",
    "                        degree = classification['radio_answer']['name']\n",
    "                        break\n",
    "        # Write to the CSV file\n",
    "        writer.writerow({'filename': external_id, 'label': degree})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted files:\n",
      "{'filename': 'img (54).txt', 'content': 'None'}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "directory = \"./kasr_aini_20240404\"  # Replace with the actual directory path\n",
    "\n",
    "deleted_files = []\n",
    "\n",
    "# Iterate over files in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith('.txt'):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        with open(file_path, 'r') as file:\n",
    "            content = file.read()\n",
    "            if 'None' in content or content.strip() == '':\n",
    "                # close the file\n",
    "                file.close()\n",
    "                # Delete the file\n",
    "                os.remove(file_path)\n",
    "                deleted_files.append({'filename': filename, 'content': content})\n",
    "\n",
    "print(\"Deleted files:\")\n",
    "for deleted_file in deleted_files:\n",
    "    print(deleted_file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
